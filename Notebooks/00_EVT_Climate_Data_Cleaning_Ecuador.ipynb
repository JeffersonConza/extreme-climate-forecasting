{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2-l3-X1O--Fl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c9f781-cf9c-4024-9ea4-97afca82a4f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (if not already mounted)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "FINAL RECOMMENDED PIPELINE (Code4 + Best Diagnostics from Code3)\n",
        "===============================================================\n",
        "\n",
        "Ecuador Climate Data Cleaning for EVT (Google Colab)\n",
        "\n",
        "What this script does\n",
        "---------------------\n",
        "✅ EVT-safe cleaning (NO outlier removal, NO imputation)\n",
        "✅ Memory-safe ingestion (chunked)\n",
        "✅ Robust datetime parsing for dt_iso strings like:\n",
        "      '1979-01-01 00:00:00 +0000 UTC'\n",
        "✅ Local time conversion using row-wise timezone offset (seconds)\n",
        "✅ Stores fecha_local as NAIVE local clock time (tz removed) to avoid misleading \"+00:00\"\n",
        "✅ Fixes city name typo: 'Lago Agrío' -> 'Lago Agrio' (removes Spanish tilde)\n",
        "✅ Drops only globally 100% null columns (detected, not hard-coded)\n",
        "✅ Optimizes dtypes: float32, downcast ints, categories for low-cardinality strings\n",
        "✅ Sort output by city_name, fecha_local (global) using:\n",
        "      chunk -> per-city parts -> per-city sort -> merge\n",
        "✅ Exports Parquet (Snappy): data_clima_clean.parquet\n",
        "\n",
        "Diagnostics added (best parts of Code3, actionable not spammy)\n",
        "--------------------------------------------------------------\n",
        "- Parse failure count\n",
        "- Timezone mismatch count (fecha_local shift check)\n",
        "- Global missingness summary (top columns)\n",
        "- Per-city row counts\n",
        "- Per-city timezone distribution (counts and percentages)\n",
        "- Duplicate timestamps per city (counts + rate) based on fecha_local\n",
        "- Max time gap per city (days) in fecha_local\n",
        "- Basic EVT preview for selected variables (min/max/quantiles) WITHOUT filtering\n",
        "\n",
        "Paths\n",
        "-----\n",
        "Input : /content/drive/MyDrive/extreme-climate-forecasting/data/data_clima.csv\n",
        "Output: /content/drive/MyDrive/extreme-climate-forecasting/data/data_clima_clean.parquet\n",
        "\n",
        "Temp dirs:\n",
        "  /content/drive/MyDrive/extreme-climate-forecasting/data/_tmp_evt_city_parts_final\n",
        "  /content/drive/MyDrive/extreme-climate-forecasting/data/_tmp_evt_city_sorted_final\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import gc\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIG\n",
        "# =============================================================================\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/extreme-climate-forecasting/data/\")\n",
        "CSV_PATH = DATA_DIR / \"data_clima.csv\"\n",
        "OUT_PARQUET = DATA_DIR / \"data_clima_clean.parquet\"\n",
        "\n",
        "TMP_PARTS_DIR = DATA_DIR / \"_tmp_evt_city_parts_final\"\n",
        "TMP_SORTED_DIR = DATA_DIR / \"_tmp_evt_city_sorted_final\"\n",
        "\n",
        "CHUNKSIZE = 300_000  # reduce if RAM errors\n",
        "\n",
        "CATEGORICAL_COLS = [\"city_name\", \"weather_main\", \"weather_description\", \"weather_icon\"]\n",
        "\n",
        "# Variables to summarize for EVT preview (non-destructive)\n",
        "EVT_PREVIEW_FLOATS = [\"temp\", \"rain_1h\", \"rain_3h\", \"wind_gust\", \"wind_speed\"]\n",
        "EVT_PREVIEW_Q = [0.95, 0.99]\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HELPERS\n",
        "# =============================================================================\n",
        "def ensure_clean_dir(path: Path) -> None:\n",
        "    if path.exists():\n",
        "        shutil.rmtree(path)\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def parse_dt_iso_to_utc(dt_iso: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Parse dt_iso strings like:\n",
        "      '1979-01-01 00:00:00 +0000 UTC'\n",
        "    into timezone-aware UTC datetimes.\n",
        "\n",
        "    We strip trailing ' UTC' and parse with explicit format for speed & consistency.\n",
        "    \"\"\"\n",
        "    s = dt_iso.astype(\"string\").str.replace(\" UTC\", \"\", regex=False)\n",
        "    return pd.to_datetime(\n",
        "        s,\n",
        "        format=\"%Y-%m-%d %H:%M:%S %z\",\n",
        "        errors=\"coerce\",\n",
        "        utc=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def optimize_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Downcast numeric types and set low-cardinality objects to category (no rounding).\"\"\"\n",
        "    # float64 -> float32\n",
        "    for c in df.select_dtypes(include=[\"float64\"]).columns:\n",
        "        df[c] = df[c].astype(\"float32\")\n",
        "\n",
        "    # int64 -> smallest safe int\n",
        "    for c in df.select_dtypes(include=[\"int64\"]).columns:\n",
        "        df[c] = pd.to_numeric(df[c], downcast=\"integer\")\n",
        "\n",
        "    # categories\n",
        "    for c in CATEGORICAL_COLS:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(\"category\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def reorder_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Identifiers/time -> location -> remaining columns.\"\"\"\n",
        "    id_time = [\n",
        "        \"city_name\",\n",
        "        \"dt\",\n",
        "        \"dt_iso\",\n",
        "        \"dt_utc\",\n",
        "        \"timezone\",\n",
        "        \"fecha_local\",\n",
        "        \"year\",\n",
        "        \"month\",\n",
        "        \"day\",\n",
        "        \"hour\",\n",
        "    ]\n",
        "    location = [\"lat\", \"lon\"]\n",
        "\n",
        "    ordered = [c for c in id_time if c in df.columns] + [c for c in location if c in df.columns]\n",
        "    remaining = [c for c in df.columns if c not in set(ordered)]\n",
        "    return df[ordered + remaining]\n",
        "\n",
        "\n",
        "def update_null_stats(df: pd.DataFrame, null_counts: Dict[str, int], nonnull_counts: Dict[str, int]) -> None:\n",
        "    n = len(df)\n",
        "    for c in df.columns:\n",
        "        miss = int(df[c].isna().sum())\n",
        "        null_counts[c] = null_counts.get(c, 0) + miss\n",
        "        nonnull_counts[c] = nonnull_counts.get(c, 0) + (n - miss)\n",
        "\n",
        "\n",
        "def update_counts(counts: Dict[str, int], series: pd.Series) -> None:\n",
        "    vc = series.value_counts(dropna=False)\n",
        "    for k, v in vc.items():\n",
        "        key = \"__NA__\" if pd.isna(k) else str(k)\n",
        "        counts[key] = counts.get(key, 0) + int(v)\n",
        "\n",
        "\n",
        "def write_city_parts(chunk: pd.DataFrame, base_dir: Path, part_counter: Dict[str, int]) -> None:\n",
        "    \"\"\"\n",
        "    Write a chunk into per-city parquet parts:\n",
        "      base_dir/city_name=Quito/part-000001.parquet\n",
        "    \"\"\"\n",
        "    city_series = chunk[\"city_name\"].astype(\"string\")\n",
        "\n",
        "    for city in city_series.unique():\n",
        "        if pd.isna(city):\n",
        "            city_key = \"__NA__\"\n",
        "            mask = city_series.isna()\n",
        "        else:\n",
        "            city_key = str(city)\n",
        "            mask = (city_series == city_key)\n",
        "\n",
        "        df_city = chunk.loc[mask].copy()\n",
        "\n",
        "        out_dir = base_dir / f\"city_name={city_key}\"\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        part_counter.setdefault(city_key, 0)\n",
        "        part_counter[city_key] += 1\n",
        "        out_file = out_dir / f\"part-{part_counter[city_key]:06d}.parquet\"\n",
        "\n",
        "        pq.write_table(pa.Table.from_pandas(df_city, preserve_index=False), out_file, compression=\"snappy\")\n",
        "        del df_city\n",
        "\n",
        "    del city_series\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "def safe_quantiles(series: pd.Series, q_list: List[float]) -> Dict[float, float]:\n",
        "    \"\"\"Compute quantiles on non-null data; return empty if no data.\"\"\"\n",
        "    s = series.dropna()\n",
        "    if len(s) == 0:\n",
        "        return {}\n",
        "    return {q: float(s.quantile(q)) for q in q_list}\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN PIPELINE\n",
        "# =============================================================================\n",
        "def clean_evt_pipeline(csv_path: Path, out_parquet: Path, chunksize: int = 300_000) -> None:\n",
        "    assert csv_path.exists(), f\"CSV not found: {csv_path}\"\n",
        "\n",
        "    ensure_clean_dir(TMP_PARTS_DIR)\n",
        "    ensure_clean_dir(TMP_SORTED_DIR)\n",
        "\n",
        "    # Global counters/stats\n",
        "    total_rows_in = 0\n",
        "    total_rows_out = 0\n",
        "\n",
        "    null_counts: Dict[str, int] = {}\n",
        "    nonnull_counts: Dict[str, int] = {}\n",
        "\n",
        "    dt_parse_fail_count = 0\n",
        "    tz_mismatch_count = 0\n",
        "\n",
        "    min_fecha_local: Optional[pd.Timestamp] = None\n",
        "    max_fecha_local: Optional[pd.Timestamp] = None\n",
        "\n",
        "    city_counts: Dict[str, int] = {}\n",
        "    timezone_counts: Dict[str, Dict[int, int]] = {}  # city -> {tz_offset: count}\n",
        "\n",
        "    # EVT preview aggregations (approx: keep global min/max and quantiles on a sample)\n",
        "    evt_minmax: Dict[str, Tuple[Optional[float], Optional[float]]] = {v: (None, None) for v in EVT_PREVIEW_FLOATS}\n",
        "    evt_sample: Dict[str, List[float]] = {v: [] for v in EVT_PREVIEW_FLOATS}\n",
        "    SAMPLE_PER_CHUNK = 3000  # keep it small; used for quantiles\n",
        "\n",
        "    part_counter: Dict[str, int] = {}\n",
        "\n",
        "    print(\"=== Phase 1: Chunked transform + per-city partition write ===\")\n",
        "    reader = pd.read_csv(csv_path, chunksize=chunksize)\n",
        "\n",
        "    for i, chunk in enumerate(reader, start=1):\n",
        "        total_rows_in += len(chunk)\n",
        "\n",
        "        # Required columns\n",
        "        for col in (\"dt_iso\", \"timezone\", \"city_name\"):\n",
        "            if col not in chunk.columns:\n",
        "                raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "        # Fix city name typo: 'Lago Agrío' -> 'Lago Agrio' (remove Spanish tilde)\n",
        "        chunk[\"city_name\"] = chunk[\"city_name\"].str.replace(\"Lago Agrío\", \"Lago Agrio\", regex=False)\n",
        "\n",
        "        # Parse dt_iso -> dt_utc\n",
        "        chunk[\"dt_utc\"] = parse_dt_iso_to_utc(chunk[\"dt_iso\"])\n",
        "        bad_dt = chunk[\"dt_utc\"].isna()\n",
        "        dt_parse_fail_count += int(bad_dt.sum())\n",
        "\n",
        "        # Shift to local time using timezone seconds, then remove tz marker -> naive local clock time\n",
        "        shifted = chunk[\"dt_utc\"] + pd.to_timedelta(chunk[\"timezone\"], unit=\"s\")\n",
        "        chunk[\"fecha_local\"] = shifted.dt.tz_localize(None)\n",
        "\n",
        "        # Extract components\n",
        "        chunk[\"year\"] = chunk[\"fecha_local\"].dt.year\n",
        "        chunk[\"month\"] = chunk[\"fecha_local\"].dt.month\n",
        "        chunk[\"day\"] = chunk[\"fecha_local\"].dt.day\n",
        "        chunk[\"hour\"] = chunk[\"fecha_local\"].dt.hour\n",
        "\n",
        "        # Timezone sanity check\n",
        "        valid = chunk[\"dt_utc\"].notna()\n",
        "        delta_sec = (shifted.loc[valid] - chunk.loc[valid, \"dt_utc\"]).dt.total_seconds()\n",
        "        tz_mismatch = (delta_sec != chunk.loc[valid, \"timezone\"].astype(\"float64\"))\n",
        "        tz_mismatch_count += int(tz_mismatch.sum())\n",
        "\n",
        "        # Global date range\n",
        "        fl = chunk[\"fecha_local\"]\n",
        "        if fl.notna().any():\n",
        "            cmin, cmax = fl.min(), fl.max()\n",
        "            min_fecha_local = cmin if (min_fecha_local is None or cmin < min_fecha_local) else min_fecha_local\n",
        "            max_fecha_local = cmax if (max_fecha_local is None or cmax > max_fecha_local) else max_fecha_local\n",
        "\n",
        "        # Null stats BEFORE dropping (so we can detect globally 100% null)\n",
        "        update_null_stats(chunk, null_counts, nonnull_counts)\n",
        "\n",
        "        # Per-city counts and timezone distribution\n",
        "        update_counts(city_counts, chunk[\"city_name\"].astype(\"string\"))\n",
        "\n",
        "        # timezone per city\n",
        "        city_ser = chunk[\"city_name\"].astype(\"string\")\n",
        "        tz_ser = chunk[\"timezone\"]\n",
        "        # lightweight group count per chunk\n",
        "        tmp = pd.DataFrame({\"city\": city_ser, \"tz\": tz_ser})\n",
        "        grp = tmp.groupby([\"city\", \"tz\"]).size()\n",
        "        for (c, tz), cnt in grp.items():\n",
        "            c_key = \"__NA__\" if pd.isna(c) else str(c)\n",
        "            timezone_counts.setdefault(c_key, {})\n",
        "            timezone_counts[c_key][int(tz)] = timezone_counts[c_key].get(int(tz), 0) + int(cnt)\n",
        "        del tmp, grp\n",
        "\n",
        "        # EVT preview: min/max and small reservoir sample per chunk\n",
        "        for v in EVT_PREVIEW_FLOATS:\n",
        "            if v in chunk.columns:\n",
        "                s = chunk[v]\n",
        "                # update min/max\n",
        "                s_non = s.dropna()\n",
        "                if len(s_non) > 0:\n",
        "                    vmin, vmax = float(s_non.min()), float(s_non.max())\n",
        "                    cur_min, cur_max = evt_minmax[v]\n",
        "                    evt_minmax[v] = (\n",
        "                        vmin if cur_min is None else min(cur_min, vmin),\n",
        "                        vmax if cur_max is None else max(cur_max, vmax),\n",
        "                    )\n",
        "\n",
        "                    # sample for quantiles\n",
        "                    take = min(SAMPLE_PER_CHUNK, len(s_non))\n",
        "                    if take > 0:\n",
        "                        evt_sample[v].extend(s_non.sample(n=take, random_state=42).astype(\"float64\").tolist())\n",
        "\n",
        "        # Optimize dtypes & reorder\n",
        "        chunk = optimize_dtypes(chunk)\n",
        "        chunk = reorder_columns(chunk)\n",
        "\n",
        "        # Partition write\n",
        "        write_city_parts(chunk, TMP_PARTS_DIR, part_counter)\n",
        "\n",
        "        total_rows_out += len(chunk)\n",
        "\n",
        "        del shifted, chunk\n",
        "        gc.collect()\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            print(f\"  processed rows so far: {total_rows_in:,}\")\n",
        "\n",
        "    # Determine globally 100% null columns (rule-based)\n",
        "    all_null_cols = sorted([c for c, nn in nonnull_counts.items() if nn == 0])\n",
        "\n",
        "    print(\"\\n=== Phase 2: Per-city sort + diagnostics (duplicates, max gap) ===\")\n",
        "    city_dirs = sorted(TMP_PARTS_DIR.glob(\"city_name=*\"), key=lambda p: p.name)\n",
        "    sorted_city_files: List[Path] = []\n",
        "\n",
        "    # City diagnostics computed on sorted per-city data (robust and actionable)\n",
        "    dup_counts: Dict[str, int] = {}\n",
        "    dup_rates: Dict[str, float] = {}\n",
        "    max_gap_days: Dict[str, Optional[int]] = {}\n",
        "\n",
        "    for city_dir in city_dirs:\n",
        "        city_name = city_dir.name.split(\"=\", 1)[1]\n",
        "\n",
        "        dataset = ds.dataset(str(city_dir), format=\"parquet\")\n",
        "        table = dataset.to_table()\n",
        "        df_city = table.to_pandas()\n",
        "\n",
        "        # Drop globally 100% null columns\n",
        "        drop_cols = [c for c in all_null_cols if c in df_city.columns]\n",
        "        if drop_cols:\n",
        "            df_city.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "        # Sort by fecha_local (within city)\n",
        "        df_city.sort_values([\"fecha_local\"], ascending=True, inplace=True, kind=\"mergesort\")\n",
        "\n",
        "        # --- Diagnostics ---\n",
        "        # Duplicate timestamps within city (fecha_local)\n",
        "        if \"fecha_local\" in df_city.columns:\n",
        "            dups = int(df_city[\"fecha_local\"].duplicated(keep=False).sum())\n",
        "            dup_counts[city_name] = dups\n",
        "            dup_rates[city_name] = (dups / len(df_city) * 100.0) if len(df_city) else 0.0\n",
        "\n",
        "            # Max gap in days between consecutive timestamps (ignoring duplicates)\n",
        "            # Use unique sorted timestamps for gap computation\n",
        "            ts = df_city[\"fecha_local\"].dropna().drop_duplicates().sort_values()\n",
        "            if len(ts) >= 2:\n",
        "                gaps = ts.diff().dropna()\n",
        "                # convert to days\n",
        "                max_gap = int(np.ceil(gaps.max() / np.timedelta64(1, \"D\")))\n",
        "                max_gap_days[city_name] = max_gap\n",
        "            else:\n",
        "                max_gap_days[city_name] = None\n",
        "\n",
        "        # Re-optimize and reorder after concatenation\n",
        "        df_city = optimize_dtypes(df_city)\n",
        "        df_city = reorder_columns(df_city)\n",
        "\n",
        "        out_city = TMP_SORTED_DIR / f\"{city_name}.parquet\"\n",
        "        pq.write_table(pa.Table.from_pandas(df_city, preserve_index=False), out_city, compression=\"snappy\")\n",
        "        sorted_city_files.append(out_city)\n",
        "\n",
        "        del table, df_city\n",
        "        gc.collect()\n",
        "\n",
        "        print(f\"  sorted city: {city_name}\")\n",
        "\n",
        "    print(\"\\n=== Phase 3: Merge sorted city files into single Parquet (Snappy) ===\")\n",
        "    if out_parquet.exists():\n",
        "        out_parquet.unlink()\n",
        "\n",
        "    writer = None\n",
        "    try:\n",
        "        for city_file in sorted(sorted_city_files, key=lambda p: p.stem):\n",
        "            t = pq.read_table(city_file)\n",
        "            if writer is None:\n",
        "                writer = pq.ParquetWriter(out_parquet, t.schema, compression=\"snappy\")\n",
        "            writer.write_table(t)\n",
        "        print(f\"✅ Wrote: {out_parquet}\")\n",
        "    finally:\n",
        "        if writer is not None:\n",
        "            writer.close()\n",
        "\n",
        "    # =============================================================================\n",
        "    # FINAL REPORT\n",
        "    # =============================================================================\n",
        "    print(\"\\n=== VALIDATION REPORT ===\")\n",
        "    print(f\"Input rows:  {total_rows_in:,}\")\n",
        "    print(f\"Output rows: {total_rows_out:,}\")\n",
        "    print(\"✅ No observation loss\" if total_rows_in == total_rows_out else \"⚠️ Row count mismatch!\")\n",
        "\n",
        "    print(f\"\\nDatetime parse failures (dt_iso -> dt_utc): {dt_parse_fail_count:,}\")\n",
        "    print(f\"Timezone mismatches (shifted - dt_utc != timezone): {tz_mismatch_count:,}\")\n",
        "\n",
        "    print(\"\\nLocal-time range (fecha_local, naive local time):\")\n",
        "    print(f\"  min: {min_fecha_local}\")\n",
        "    print(f\"  max: {max_fecha_local}\")\n",
        "\n",
        "    print(\"\\nGlobally 100% null columns detected (dropped):\")\n",
        "    print(all_null_cols if all_null_cols else \"(none)\")\n",
        "\n",
        "    # Missingness (top 15)\n",
        "    miss_df = pd.DataFrame({\n",
        "        \"column\": list(null_counts.keys()),\n",
        "        \"missing_count\": list(null_counts.values()),\n",
        "        \"missing_pct\": [100.0 * null_counts[c] / total_rows_in for c in null_counts.keys()],\n",
        "    }).sort_values(\"missing_pct\", ascending=False)\n",
        "\n",
        "    print(\"\\nMost-missing columns (top 15):\")\n",
        "    print(miss_df.head(15).to_string(index=False))\n",
        "\n",
        "    print(\"\\nCity counts:\")\n",
        "    for c in sorted(city_counts.keys()):\n",
        "        print(f\"  {c}: {city_counts[c]:,}\")\n",
        "\n",
        "    # Timezone distribution per city (compact)\n",
        "    print(\"\\nTimezone distribution per city (seconds offset):\")\n",
        "    for c in sorted(timezone_counts.keys()):\n",
        "        total = sum(timezone_counts[c].values())\n",
        "        parts = []\n",
        "        for tz in sorted(timezone_counts[c].keys()):\n",
        "            cnt = timezone_counts[c][tz]\n",
        "            parts.append(f\"{tz}:{cnt} ({cnt/total*100:.2f}%)\")\n",
        "        print(f\"  {c}: \" + \", \".join(parts))\n",
        "\n",
        "    # Duplicate timestamps + max gap diagnostics\n",
        "    print(\"\\nDuplicate timestamps per city (fecha_local):\")\n",
        "    for c in sorted(dup_counts.keys()):\n",
        "        print(f\"  {c}: {dup_counts[c]:,}  ({dup_rates[c]:.4f}%)\")\n",
        "\n",
        "    print(\"\\nMax gap between unique timestamps per city (days):\")\n",
        "    for c in sorted(max_gap_days.keys()):\n",
        "        print(f\"  {c}: {max_gap_days[c]}\")\n",
        "\n",
        "    # EVT preview (approx quantiles from samples)\n",
        "    print(\"\\nEVT preview (non-destructive):\")\n",
        "    for v in EVT_PREVIEW_FLOATS:\n",
        "        if evt_minmax[v][0] is None:\n",
        "            continue\n",
        "        q = safe_quantiles(pd.Series(evt_sample[v], dtype=\"float64\"), EVT_PREVIEW_Q)\n",
        "        print(f\"  {v}: min={evt_minmax[v][0]:.4g}, max={evt_minmax[v][1]:.4g}, \"\n",
        "              + \", \".join([f\"q{int(qq*100)}={q[qq]:.4g}\" for qq in q]))\n",
        "\n",
        "    # Final schema\n",
        "    try:\n",
        "        schema = pq.read_schema(out_parquet)\n",
        "        print(\"\\nFinal Parquet schema:\")\n",
        "        print(schema)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n(Info) Could not read final schema: {e}\")\n",
        "\n",
        "    print(\"\\n=== Done ===\")\n",
        "\n",
        "    # Optional cleanup\n",
        "    # shutil.rmtree(TMP_PARTS_DIR, ignore_errors=True)\n",
        "    # shutil.rmtree(TMP_SORTED_DIR, ignore_errors=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    clean_evt_pipeline(csv_path=CSV_PATH, out_parquet=OUT_PARQUET, chunksize=CHUNKSIZE)\n"
      ],
      "metadata": {
        "id": "_-w-WtQ9_8OY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecabfc75-6879-4a52-8479-4426344e7f1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Phase 1: Chunked transform + per-city partition write ===\n",
            "  processed rows so far: 1,500,000\n",
            "  processed rows so far: 3,000,000\n",
            "  processed rows so far: 4,500,000\n",
            "  processed rows so far: 6,000,000\n",
            "\n",
            "=== Phase 2: Per-city sort + diagnostics (duplicates, max gap) ===\n",
            "  sorted city: Ambato\n",
            "  sorted city: Cuenca\n",
            "  sorted city: Esmeraldas\n",
            "  sorted city: Guayaquil\n",
            "  sorted city: Ibarra\n",
            "  sorted city: Lago Agrio\n",
            "  sorted city: Loja\n",
            "  sorted city: Machala\n",
            "  sorted city: Manta\n",
            "  sorted city: Puerto Morona\n",
            "  sorted city: Puyo\n",
            "  sorted city: Quevedo\n",
            "  sorted city: Quito\n",
            "  sorted city: Santa Cruz Island\n",
            "  sorted city: Santo Domingo\n",
            "  sorted city: Zamora\n",
            "\n",
            "=== Phase 3: Merge sorted city files into single Parquet (Snappy) ===\n",
            "✅ Wrote: /content/drive/MyDrive/extreme-climate-forecasting/data/data_clima_clean.parquet\n",
            "\n",
            "=== VALIDATION REPORT ===\n",
            "Input rows:  6,445,858\n",
            "Output rows: 6,445,858\n",
            "✅ No observation loss\n",
            "\n",
            "Datetime parse failures (dt_iso -> dt_utc): 0\n",
            "Timezone mismatches (shifted - dt_utc != timezone): 0\n",
            "\n",
            "Local-time range (fecha_local, naive local time):\n",
            "  min: 1978-12-31 19:00:00\n",
            "  max: 2024-10-19 18:00:00\n",
            "\n",
            "Globally 100% null columns detected (dropped):\n",
            "['grnd_level', 'sea_level', 'snow_1h', 'snow_3h']\n",
            "\n",
            "Most-missing columns (top 15):\n",
            "    column  missing_count  missing_pct\n",
            " sea_level        6445858   100.000000\n",
            "grnd_level        6445858   100.000000\n",
            "   snow_3h        6445858   100.000000\n",
            "   snow_1h        6445858   100.000000\n",
            "   rain_3h        6444360    99.976760\n",
            " wind_gust        6389392    99.123996\n",
            "visibility        5409494    83.922016\n",
            "   rain_1h        4134594    64.143424\n",
            "    dt_iso              0     0.000000\n",
            "        dt              0     0.000000\n",
            "feels_like              0     0.000000\n",
            " dew_point              0     0.000000\n",
            "  temp_max              0     0.000000\n",
            "  timezone              0     0.000000\n",
            "       lon              0     0.000000\n",
            "\n",
            "City counts:\n",
            "  Ambato: 402,756\n",
            "  Cuenca: 402,742\n",
            "  Esmeraldas: 401,736\n",
            "  Guayaquil: 404,863\n",
            "  Ibarra: 401,583\n",
            "  Lago Agrio: 401,840\n",
            "  Loja: 402,203\n",
            "  Machala: 402,243\n",
            "  Manta: 401,766\n",
            "  Puerto Morona: 401,496\n",
            "  Puyo: 403,356\n",
            "  Quevedo: 402,121\n",
            "  Quito: 411,112\n",
            "  Santa Cruz Island: 401,496\n",
            "  Santo Domingo: 403,049\n",
            "  Zamora: 401,496\n",
            "\n",
            "Timezone distribution per city (seconds offset):\n",
            "  Ambato: -18000:401100 (99.59%), -14400:1656 (0.41%)\n",
            "  Cuenca: -18000:401083 (99.59%), -14400:1659 (0.41%)\n",
            "  Esmeraldas: -18000:400080 (99.59%), -14400:1656 (0.41%)\n",
            "  Guayaquil: -18000:403175 (99.58%), -14400:1688 (0.42%)\n",
            "  Ibarra: -18000:399927 (99.59%), -14400:1656 (0.41%)\n",
            "  Lago Agrio: -18000:400185 (99.59%), -14400:1655 (0.41%)\n",
            "  Loja: -18000:400545 (99.59%), -14400:1658 (0.41%)\n",
            "  Machala: -18000:400587 (99.59%), -14400:1656 (0.41%)\n",
            "  Manta: -18000:400111 (99.59%), -14400:1655 (0.41%)\n",
            "  Puerto Morona: -18000:399841 (99.59%), -14400:1655 (0.41%)\n",
            "  Puyo: -18000:401697 (99.59%), -14400:1659 (0.41%)\n",
            "  Quevedo: -18000:400466 (99.59%), -14400:1655 (0.41%)\n",
            "  Quito: -18000:409439 (99.59%), -14400:1673 (0.41%)\n",
            "  Santa Cruz Island: -21600:338468 (84.30%), -18000:63028 (15.70%)\n",
            "  Santo Domingo: -18000:401394 (99.59%), -14400:1655 (0.41%)\n",
            "  Zamora: -18000:399841 (99.59%), -14400:1655 (0.41%)\n",
            "\n",
            "Duplicate timestamps per city (fecha_local):\n",
            "  Ambato: 2,483  (0.6165%)\n",
            "  Cuenca: 2,478  (0.6153%)\n",
            "  Esmeraldas: 480  (0.1195%)\n",
            "  Guayaquil: 6,729  (1.6620%)\n",
            "  Ibarra: 176  (0.0438%)\n",
            "  Lago Agrio: 682  (0.1697%)\n",
            "  Loja: 1,416  (0.3521%)\n",
            "  Machala: 1,496  (0.3719%)\n",
            "  Manta: 542  (0.1349%)\n",
            "  Puerto Morona: 2  (0.0005%)\n",
            "  Puyo: 3,720  (0.9223%)\n",
            "  Quevedo: 1,250  (0.3109%)\n",
            "  Quito: 18,842  (4.5832%)\n",
            "  Santa Cruz Island: 4  (0.0010%)\n",
            "  Santo Domingo: 2,795  (0.6935%)\n",
            "  Zamora: 2  (0.0005%)\n",
            "\n",
            "Max gap between unique timestamps per city (days):\n",
            "  Ambato: 1\n",
            "  Cuenca: 1\n",
            "  Esmeraldas: 1\n",
            "  Guayaquil: 1\n",
            "  Ibarra: 1\n",
            "  Lago Agrio: 1\n",
            "  Loja: 1\n",
            "  Machala: 1\n",
            "  Manta: 1\n",
            "  Puerto Morona: 1\n",
            "  Puyo: 1\n",
            "  Quevedo: 1\n",
            "  Quito: 1\n",
            "  Santa Cruz Island: 1\n",
            "  Santo Domingo: 1\n",
            "  Zamora: 1\n",
            "\n",
            "EVT preview (non-destructive):\n",
            "  temp: min=0.19, max=38.93, q95=28.6, q99=30.78\n",
            "  rain_1h: min=0.1, max=48.77, q95=2.28, q99=4.78\n",
            "  rain_3h: min=0.13, max=49, q95=3.56, q99=5.69\n",
            "  wind_gust: min=0, max=149.2, q95=10.3, q99=13.86\n",
            "  wind_speed: min=0, max=86.24, q95=5.1, q99=6.51\n",
            "\n",
            "Final Parquet schema:\n",
            "city_name: dictionary<values=string, indices=int32, ordered=0>\n",
            "dt: int32\n",
            "dt_iso: string\n",
            "dt_utc: timestamp[ns, tz=UTC]\n",
            "timezone: int16\n",
            "fecha_local: timestamp[ns]\n",
            "year: int32\n",
            "month: int32\n",
            "day: int32\n",
            "hour: int32\n",
            "lat: float\n",
            "lon: float\n",
            "temp: float\n",
            "visibility: float\n",
            "dew_point: float\n",
            "feels_like: float\n",
            "temp_min: float\n",
            "temp_max: float\n",
            "pressure: int16\n",
            "humidity: int8\n",
            "wind_speed: float\n",
            "wind_deg: int16\n",
            "wind_gust: float\n",
            "rain_1h: float\n",
            "rain_3h: float\n",
            "clouds_all: int8\n",
            "weather_id: int16\n",
            "weather_main: dictionary<values=string, indices=int32, ordered=0>\n",
            "weather_description: dictionary<values=string, indices=int32, ordered=0>\n",
            "weather_icon: dictionary<values=string, indices=int32, ordered=0>\n",
            "-- schema metadata --\n",
            "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 3702\n",
            "\n",
            "=== Done ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check dataset"
      ],
      "metadata": {
        "id": "GqYntD_WAGep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "my_file = 'data_clima_clean.parquet'\n",
        "file_path = f'/content/drive/MyDrive/extreme-climate-forecasting/data/{my_file}'\n",
        "\n",
        "try:\n",
        "    # data = pd.read_csv(file_path)   # dataset name\n",
        "    data = pd.read_parquet(file_path)\n",
        "    print(f\"Shape: {data.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")"
      ],
      "metadata": {
        "id": "OGXKFlEmAITq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed591b8-4b3b-4da9-b5fe-be83edcded9e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (6445858, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "E969i8vSAPhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980b9b4f-0dc3-4042-8b63-b08ad4258928"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6445858 entries, 0 to 6445857\n",
            "Data columns (total 30 columns):\n",
            " #   Column               Dtype              \n",
            "---  ------               -----              \n",
            " 0   city_name            category           \n",
            " 1   dt                   int32              \n",
            " 2   dt_iso               object             \n",
            " 3   dt_utc               datetime64[ns, UTC]\n",
            " 4   timezone             int16              \n",
            " 5   fecha_local          datetime64[ns]     \n",
            " 6   year                 int32              \n",
            " 7   month                int32              \n",
            " 8   day                  int32              \n",
            " 9   hour                 int32              \n",
            " 10  lat                  float32            \n",
            " 11  lon                  float32            \n",
            " 12  temp                 float32            \n",
            " 13  visibility           float32            \n",
            " 14  dew_point            float32            \n",
            " 15  feels_like           float32            \n",
            " 16  temp_min             float32            \n",
            " 17  temp_max             float32            \n",
            " 18  pressure             int16              \n",
            " 19  humidity             int8               \n",
            " 20  wind_speed           float32            \n",
            " 21  wind_deg             int16              \n",
            " 22  wind_gust            float32            \n",
            " 23  rain_1h              float32            \n",
            " 24  rain_3h              float32            \n",
            " 25  clouds_all           int8               \n",
            " 26  weather_id           int16              \n",
            " 27  weather_main         category           \n",
            " 28  weather_description  category           \n",
            " 29  weather_icon         category           \n",
            "dtypes: category(4), datetime64[ns, UTC](1), datetime64[ns](1), float32(12), int16(4), int32(5), int8(2), object(1)\n",
            "memory usage: 651.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data # head and tail"
      ],
      "metadata": {
        "id": "GyHfszl3AOkk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "533f77d6-1921-44d6-b759-768c7229ee37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        city_name          dt                         dt_iso  \\\n",
              "0          Ambato   283996800  1979-01-01 00:00:00 +0000 UTC   \n",
              "1          Ambato   284000400  1979-01-01 01:00:00 +0000 UTC   \n",
              "2          Ambato   284004000  1979-01-01 02:00:00 +0000 UTC   \n",
              "3          Ambato   284007600  1979-01-01 03:00:00 +0000 UTC   \n",
              "4          Ambato   284011200  1979-01-01 04:00:00 +0000 UTC   \n",
              "...           ...         ...                            ...   \n",
              "6445853    Zamora  1729364400  2024-10-19 19:00:00 +0000 UTC   \n",
              "6445854    Zamora  1729368000  2024-10-19 20:00:00 +0000 UTC   \n",
              "6445855    Zamora  1729371600  2024-10-19 21:00:00 +0000 UTC   \n",
              "6445856    Zamora  1729375200  2024-10-19 22:00:00 +0000 UTC   \n",
              "6445857    Zamora  1729378800  2024-10-19 23:00:00 +0000 UTC   \n",
              "\n",
              "                           dt_utc  timezone         fecha_local  year  month  \\\n",
              "0       1979-01-01 00:00:00+00:00    -18000 1978-12-31 19:00:00  1978     12   \n",
              "1       1979-01-01 01:00:00+00:00    -18000 1978-12-31 20:00:00  1978     12   \n",
              "2       1979-01-01 02:00:00+00:00    -18000 1978-12-31 21:00:00  1978     12   \n",
              "3       1979-01-01 03:00:00+00:00    -18000 1978-12-31 22:00:00  1978     12   \n",
              "4       1979-01-01 04:00:00+00:00    -18000 1978-12-31 23:00:00  1978     12   \n",
              "...                           ...       ...                 ...   ...    ...   \n",
              "6445853 2024-10-19 19:00:00+00:00    -18000 2024-10-19 14:00:00  2024     10   \n",
              "6445854 2024-10-19 20:00:00+00:00    -18000 2024-10-19 15:00:00  2024     10   \n",
              "6445855 2024-10-19 21:00:00+00:00    -18000 2024-10-19 16:00:00  2024     10   \n",
              "6445856 2024-10-19 22:00:00+00:00    -18000 2024-10-19 17:00:00  2024     10   \n",
              "6445857 2024-10-19 23:00:00+00:00    -18000 2024-10-19 18:00:00  2024     10   \n",
              "\n",
              "         day  hour  ...  wind_speed  wind_deg  wind_gust  rain_1h  rain_3h  \\\n",
              "0         31    19  ...        1.88       112        NaN      NaN      NaN   \n",
              "1         31    20  ...        1.68       101        NaN      NaN      NaN   \n",
              "2         31    21  ...        1.51       103        NaN      NaN      NaN   \n",
              "3         31    22  ...        1.47       107        NaN      NaN      NaN   \n",
              "4         31    23  ...        1.45       111        NaN      NaN      NaN   \n",
              "...      ...   ...  ...         ...       ...        ...      ...      ...   \n",
              "6445853   19    14  ...        2.64        88       1.80      NaN      NaN   \n",
              "6445854   19    15  ...        2.36        58       3.01      NaN      NaN   \n",
              "6445855   19    16  ...        2.36        58       3.01      NaN      NaN   \n",
              "6445856   19    17  ...        2.36        58       3.01      NaN      NaN   \n",
              "6445857   19    18  ...        1.69        11       1.53      NaN      NaN   \n",
              "\n",
              "         clouds_all  weather_id  weather_main  weather_description  \\\n",
              "0                44         802        Clouds     scattered clouds   \n",
              "1                92         804        Clouds      overcast clouds   \n",
              "2                93         804        Clouds      overcast clouds   \n",
              "3                93         804        Clouds      overcast clouds   \n",
              "4                95         804        Clouds      overcast clouds   \n",
              "...             ...         ...           ...                  ...   \n",
              "6445853          55         803        Clouds        broken clouds   \n",
              "6445854          54         803        Clouds        broken clouds   \n",
              "6445855          54         803        Clouds        broken clouds   \n",
              "6445856          54         803        Clouds        broken clouds   \n",
              "6445857         100         804        Clouds      overcast clouds   \n",
              "\n",
              "         weather_icon  \n",
              "0                 03n  \n",
              "1                 04n  \n",
              "2                 04n  \n",
              "3                 04n  \n",
              "4                 04n  \n",
              "...               ...  \n",
              "6445853           04d  \n",
              "6445854           04d  \n",
              "6445855           04d  \n",
              "6445856           04d  \n",
              "6445857           04d  \n",
              "\n",
              "[6445858 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1964dad9-70b9-431e-8c02-79f71283a890\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city_name</th>\n",
              "      <th>dt</th>\n",
              "      <th>dt_iso</th>\n",
              "      <th>dt_utc</th>\n",
              "      <th>timezone</th>\n",
              "      <th>fecha_local</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>...</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_deg</th>\n",
              "      <th>wind_gust</th>\n",
              "      <th>rain_1h</th>\n",
              "      <th>rain_3h</th>\n",
              "      <th>clouds_all</th>\n",
              "      <th>weather_id</th>\n",
              "      <th>weather_main</th>\n",
              "      <th>weather_description</th>\n",
              "      <th>weather_icon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ambato</td>\n",
              "      <td>283996800</td>\n",
              "      <td>1979-01-01 00:00:00 +0000 UTC</td>\n",
              "      <td>1979-01-01 00:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>1978-12-31 19:00:00</td>\n",
              "      <td>1978</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>1.88</td>\n",
              "      <td>112</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44</td>\n",
              "      <td>802</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>scattered clouds</td>\n",
              "      <td>03n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ambato</td>\n",
              "      <td>284000400</td>\n",
              "      <td>1979-01-01 01:00:00 +0000 UTC</td>\n",
              "      <td>1979-01-01 01:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>1978-12-31 20:00:00</td>\n",
              "      <td>1978</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>20</td>\n",
              "      <td>...</td>\n",
              "      <td>1.68</td>\n",
              "      <td>101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>92</td>\n",
              "      <td>804</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>04n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ambato</td>\n",
              "      <td>284004000</td>\n",
              "      <td>1979-01-01 02:00:00 +0000 UTC</td>\n",
              "      <td>1979-01-01 02:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>1978-12-31 21:00:00</td>\n",
              "      <td>1978</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>1.51</td>\n",
              "      <td>103</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93</td>\n",
              "      <td>804</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>04n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ambato</td>\n",
              "      <td>284007600</td>\n",
              "      <td>1979-01-01 03:00:00 +0000 UTC</td>\n",
              "      <td>1979-01-01 03:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>1978-12-31 22:00:00</td>\n",
              "      <td>1978</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>1.47</td>\n",
              "      <td>107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93</td>\n",
              "      <td>804</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>04n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ambato</td>\n",
              "      <td>284011200</td>\n",
              "      <td>1979-01-01 04:00:00 +0000 UTC</td>\n",
              "      <td>1979-01-01 04:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>1978-12-31 23:00:00</td>\n",
              "      <td>1978</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>1.45</td>\n",
              "      <td>111</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>95</td>\n",
              "      <td>804</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>04n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6445853</th>\n",
              "      <td>Zamora</td>\n",
              "      <td>1729364400</td>\n",
              "      <td>2024-10-19 19:00:00 +0000 UTC</td>\n",
              "      <td>2024-10-19 19:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>2024-10-19 14:00:00</td>\n",
              "      <td>2024</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>2.64</td>\n",
              "      <td>88</td>\n",
              "      <td>1.80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55</td>\n",
              "      <td>803</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>04d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6445854</th>\n",
              "      <td>Zamora</td>\n",
              "      <td>1729368000</td>\n",
              "      <td>2024-10-19 20:00:00 +0000 UTC</td>\n",
              "      <td>2024-10-19 20:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>2024-10-19 15:00:00</td>\n",
              "      <td>2024</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>2.36</td>\n",
              "      <td>58</td>\n",
              "      <td>3.01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54</td>\n",
              "      <td>803</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>04d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6445855</th>\n",
              "      <td>Zamora</td>\n",
              "      <td>1729371600</td>\n",
              "      <td>2024-10-19 21:00:00 +0000 UTC</td>\n",
              "      <td>2024-10-19 21:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>2024-10-19 16:00:00</td>\n",
              "      <td>2024</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>2.36</td>\n",
              "      <td>58</td>\n",
              "      <td>3.01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54</td>\n",
              "      <td>803</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>04d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6445856</th>\n",
              "      <td>Zamora</td>\n",
              "      <td>1729375200</td>\n",
              "      <td>2024-10-19 22:00:00 +0000 UTC</td>\n",
              "      <td>2024-10-19 22:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>2024-10-19 17:00:00</td>\n",
              "      <td>2024</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>2.36</td>\n",
              "      <td>58</td>\n",
              "      <td>3.01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54</td>\n",
              "      <td>803</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>04d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6445857</th>\n",
              "      <td>Zamora</td>\n",
              "      <td>1729378800</td>\n",
              "      <td>2024-10-19 23:00:00 +0000 UTC</td>\n",
              "      <td>2024-10-19 23:00:00+00:00</td>\n",
              "      <td>-18000</td>\n",
              "      <td>2024-10-19 18:00:00</td>\n",
              "      <td>2024</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>...</td>\n",
              "      <td>1.69</td>\n",
              "      <td>11</td>\n",
              "      <td>1.53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>804</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>04d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6445858 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1964dad9-70b9-431e-8c02-79f71283a890')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1964dad9-70b9-431e-8c02-79f71283a890 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1964dad9-70b9-431e-8c02-79f71283a890');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_e61a77c2-c254-4e23-aee4-a62054c3d731\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e61a77c2-c254-4e23-aee4-a62054c3d731 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()    # Get summary statistics"
      ],
      "metadata": {
        "id": "PQD2YjIeAIxi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "02a9e2b0-a622-4113-93fa-c99993593ad4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 dt      timezone                    fecha_local  \\\n",
              "count  6.445858e+06  6.445858e+06                        6445858   \n",
              "mean   1.007273e+09 -1.817513e+04  2001-12-02 00:58:41.613666688   \n",
              "min    2.839968e+08 -2.160000e+04            1978-12-31 19:00:00   \n",
              "25%    6.460164e+08 -1.800000e+04            1990-06-21 20:00:00   \n",
              "50%    1.007658e+09 -1.800000e+04            2001-12-06 12:00:00   \n",
              "75%    1.368598e+09 -1.800000e+04            2013-05-15 01:00:00   \n",
              "max    1.729379e+09 -1.440000e+04            2024-10-19 18:00:00   \n",
              "std    4.172152e+08  8.365979e+02                            NaN   \n",
              "\n",
              "               year         month           day          hour           lat  \\\n",
              "count  6.445858e+06  6.445858e+06  6.445858e+06  6.445858e+06  6.445858e+06   \n",
              "mean   2.001420e+03  6.499152e+00  1.572299e+01  1.150095e+01 -1.480567e+00   \n",
              "min    1.978000e+03  1.000000e+00  1.000000e+00  0.000000e+00 -4.062094e+00   \n",
              "25%    1.990000e+03  4.000000e+00  8.000000e+00  6.000000e+00 -2.882745e+00   \n",
              "50%    2.001000e+03  7.000000e+00  1.600000e+01  1.200000e+01 -1.022512e+00   \n",
              "75%    2.013000e+03  9.000000e+00  2.300000e+01  1.700000e+01 -2.232520e-01   \n",
              "max    2.024000e+03  1.200000e+01  3.100000e+01  2.300000e+01  9.705810e-01   \n",
              "std    1.322073e+01  3.443060e+00  8.798920e+00  6.920700e+00  1.538459e+00   \n",
              "\n",
              "                lon          temp  ...      temp_max      pressure  \\\n",
              "count  6.445858e+06  6.445858e+06  ...  6.445858e+06  6.445858e+06   \n",
              "mean  -7.963538e+01  2.110215e+01  ...  2.206570e+01  1.013676e+03   \n",
              "min   -9.033719e+01  1.900000e-01  ...  1.990000e+00  1.001000e+03   \n",
              "25%   -7.965300e+01  1.758000e+01  ...  1.885000e+01  1.011000e+03   \n",
              "50%   -7.900590e+01  2.194000e+01  ...  2.274000e+01  1.013000e+03   \n",
              "75%   -7.851411e+01  2.465000e+01  ...  2.537000e+01  1.016000e+03   \n",
              "max   -7.691194e+01  3.893000e+01  ...  3.946000e+01  1.029000e+03   \n",
              "std    5.083071e+00  4.984807e+00  ...  4.784522e+00  3.627487e+00   \n",
              "\n",
              "           humidity    wind_speed      wind_deg     wind_gust       rain_1h  \\\n",
              "count  6.445858e+06  6.445858e+06  6.445858e+06  56466.000000  2.311264e+06   \n",
              "mean   8.419744e+01  1.924652e+00  1.818743e+02      2.135571  6.772044e-01   \n",
              "min    1.000000e+00  0.000000e+00  0.000000e+00      0.000000  1.000000e-01   \n",
              "25%    7.800000e+01  8.900000e-01  1.010000e+02      0.000000  1.800000e-01   \n",
              "50%    8.700000e+01  1.500000e+00  1.840000e+02      0.000000  3.400000e-01   \n",
              "75%    9.300000e+01  2.600000e+00  2.610000e+02      3.130000  7.600000e-01   \n",
              "max    1.000000e+02  8.624000e+01  3.600000e+02    149.199997  4.877000e+01   \n",
              "std    1.224997e+01  1.469900e+00  9.260996e+01      3.655935  1.018558e+00   \n",
              "\n",
              "           rain_3h    clouds_all    weather_id  \n",
              "count  1498.000000  6.445858e+06  6.445858e+06  \n",
              "mean      1.307477  7.948018e+01  6.910056e+02  \n",
              "min       0.130000  0.000000e+00  2.000000e+02  \n",
              "25%       0.645000  6.900000e+01  5.000000e+02  \n",
              "50%       1.000000  9.200000e+01  8.020000e+02  \n",
              "75%       1.130000  9.900000e+01  8.040000e+02  \n",
              "max      49.000000  1.000000e+02  8.040000e+02  \n",
              "std       2.128318  2.551184e+01  1.461824e+02  \n",
              "\n",
              "[8 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5db42787-bd17-417d-8571-5813466f309c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dt</th>\n",
              "      <th>timezone</th>\n",
              "      <th>fecha_local</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>temp</th>\n",
              "      <th>...</th>\n",
              "      <th>temp_max</th>\n",
              "      <th>pressure</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_deg</th>\n",
              "      <th>wind_gust</th>\n",
              "      <th>rain_1h</th>\n",
              "      <th>rain_3h</th>\n",
              "      <th>clouds_all</th>\n",
              "      <th>weather_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6445858</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>56466.000000</td>\n",
              "      <td>2.311264e+06</td>\n",
              "      <td>1498.000000</td>\n",
              "      <td>6.445858e+06</td>\n",
              "      <td>6.445858e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.007273e+09</td>\n",
              "      <td>-1.817513e+04</td>\n",
              "      <td>2001-12-02 00:58:41.613666688</td>\n",
              "      <td>2.001420e+03</td>\n",
              "      <td>6.499152e+00</td>\n",
              "      <td>1.572299e+01</td>\n",
              "      <td>1.150095e+01</td>\n",
              "      <td>-1.480567e+00</td>\n",
              "      <td>-7.963538e+01</td>\n",
              "      <td>2.110215e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.206570e+01</td>\n",
              "      <td>1.013676e+03</td>\n",
              "      <td>8.419744e+01</td>\n",
              "      <td>1.924652e+00</td>\n",
              "      <td>1.818743e+02</td>\n",
              "      <td>2.135571</td>\n",
              "      <td>6.772044e-01</td>\n",
              "      <td>1.307477</td>\n",
              "      <td>7.948018e+01</td>\n",
              "      <td>6.910056e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.839968e+08</td>\n",
              "      <td>-2.160000e+04</td>\n",
              "      <td>1978-12-31 19:00:00</td>\n",
              "      <td>1.978000e+03</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-4.062094e+00</td>\n",
              "      <td>-9.033719e+01</td>\n",
              "      <td>1.900000e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.990000e+00</td>\n",
              "      <td>1.001000e+03</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.460164e+08</td>\n",
              "      <td>-1.800000e+04</td>\n",
              "      <td>1990-06-21 20:00:00</td>\n",
              "      <td>1.990000e+03</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>8.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>-2.882745e+00</td>\n",
              "      <td>-7.965300e+01</td>\n",
              "      <td>1.758000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.885000e+01</td>\n",
              "      <td>1.011000e+03</td>\n",
              "      <td>7.800000e+01</td>\n",
              "      <td>8.900000e-01</td>\n",
              "      <td>1.010000e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.800000e-01</td>\n",
              "      <td>0.645000</td>\n",
              "      <td>6.900000e+01</td>\n",
              "      <td>5.000000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.007658e+09</td>\n",
              "      <td>-1.800000e+04</td>\n",
              "      <td>2001-12-06 12:00:00</td>\n",
              "      <td>2.001000e+03</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>1.600000e+01</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>-1.022512e+00</td>\n",
              "      <td>-7.900590e+01</td>\n",
              "      <td>2.194000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.274000e+01</td>\n",
              "      <td>1.013000e+03</td>\n",
              "      <td>8.700000e+01</td>\n",
              "      <td>1.500000e+00</td>\n",
              "      <td>1.840000e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.400000e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.200000e+01</td>\n",
              "      <td>8.020000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.368598e+09</td>\n",
              "      <td>-1.800000e+04</td>\n",
              "      <td>2013-05-15 01:00:00</td>\n",
              "      <td>2.013000e+03</td>\n",
              "      <td>9.000000e+00</td>\n",
              "      <td>2.300000e+01</td>\n",
              "      <td>1.700000e+01</td>\n",
              "      <td>-2.232520e-01</td>\n",
              "      <td>-7.851411e+01</td>\n",
              "      <td>2.465000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.537000e+01</td>\n",
              "      <td>1.016000e+03</td>\n",
              "      <td>9.300000e+01</td>\n",
              "      <td>2.600000e+00</td>\n",
              "      <td>2.610000e+02</td>\n",
              "      <td>3.130000</td>\n",
              "      <td>7.600000e-01</td>\n",
              "      <td>1.130000</td>\n",
              "      <td>9.900000e+01</td>\n",
              "      <td>8.040000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.729379e+09</td>\n",
              "      <td>-1.440000e+04</td>\n",
              "      <td>2024-10-19 18:00:00</td>\n",
              "      <td>2.024000e+03</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>3.100000e+01</td>\n",
              "      <td>2.300000e+01</td>\n",
              "      <td>9.705810e-01</td>\n",
              "      <td>-7.691194e+01</td>\n",
              "      <td>3.893000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>3.946000e+01</td>\n",
              "      <td>1.029000e+03</td>\n",
              "      <td>1.000000e+02</td>\n",
              "      <td>8.624000e+01</td>\n",
              "      <td>3.600000e+02</td>\n",
              "      <td>149.199997</td>\n",
              "      <td>4.877000e+01</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>1.000000e+02</td>\n",
              "      <td>8.040000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.172152e+08</td>\n",
              "      <td>8.365979e+02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.322073e+01</td>\n",
              "      <td>3.443060e+00</td>\n",
              "      <td>8.798920e+00</td>\n",
              "      <td>6.920700e+00</td>\n",
              "      <td>1.538459e+00</td>\n",
              "      <td>5.083071e+00</td>\n",
              "      <td>4.984807e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>4.784522e+00</td>\n",
              "      <td>3.627487e+00</td>\n",
              "      <td>1.224997e+01</td>\n",
              "      <td>1.469900e+00</td>\n",
              "      <td>9.260996e+01</td>\n",
              "      <td>3.655935</td>\n",
              "      <td>1.018558e+00</td>\n",
              "      <td>2.128318</td>\n",
              "      <td>2.551184e+01</td>\n",
              "      <td>1.461824e+02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5db42787-bd17-417d-8571-5813466f309c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5db42787-bd17-417d-8571-5813466f309c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5db42787-bd17-417d-8571-5813466f309c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unique values"
      ],
      "metadata": {
        "id": "Ac8eTS3jAaRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks unique values in every column\n",
        "for col in data.columns:\n",
        "    unique_values = data[col].unique()\n",
        "    print(f\"Column '{col}':\")\n",
        "    print(unique_values)\n",
        "    print(f\"Number of unique values: {len(unique_values)}\")\n",
        "    print(\"-\" * 60)\n",
        "    print()"
      ],
      "metadata": {
        "id": "Qrap6K2ZAbzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ff02fd-5201-46c0-ae8a-4fee628f259e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'city_name':\n",
            "['Ambato', 'Cuenca', 'Esmeraldas', 'Guayaquil', 'Ibarra', ..., 'Quevedo', 'Quito', 'Santa Cruz Island', 'Santo Domingo', 'Zamora']\n",
            "Length: 16\n",
            "Categories (16, object): ['Ambato', 'Cuenca', 'Quito', 'Santo Domingo', ..., 'Manta', 'Quevedo',\n",
            "                          'Puerto Morona', 'Santa Cruz Island']\n",
            "Number of unique values: 16\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'dt':\n",
            "[ 283996800  284000400  284004000 ... 1729371600 1729375200 1729378800]\n",
            "Number of unique values: 401496\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'dt_iso':\n",
            "['1979-01-01 00:00:00 +0000 UTC' '1979-01-01 01:00:00 +0000 UTC'\n",
            " '1979-01-01 02:00:00 +0000 UTC' ... '2024-10-19 21:00:00 +0000 UTC'\n",
            " '2024-10-19 22:00:00 +0000 UTC' '2024-10-19 23:00:00 +0000 UTC']\n",
            "Number of unique values: 401496\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'dt_utc':\n",
            "<DatetimeArray>\n",
            "['1979-01-01 00:00:00+00:00', '1979-01-01 01:00:00+00:00',\n",
            " '1979-01-01 02:00:00+00:00', '1979-01-01 03:00:00+00:00',\n",
            " '1979-01-01 04:00:00+00:00', '1979-01-01 05:00:00+00:00',\n",
            " '1979-01-01 06:00:00+00:00', '1979-01-01 07:00:00+00:00',\n",
            " '1979-01-01 08:00:00+00:00', '1979-01-01 09:00:00+00:00',\n",
            " ...\n",
            " '2024-10-19 14:00:00+00:00', '2024-10-19 15:00:00+00:00',\n",
            " '2024-10-19 16:00:00+00:00', '2024-10-19 17:00:00+00:00',\n",
            " '2024-10-19 18:00:00+00:00', '2024-10-19 19:00:00+00:00',\n",
            " '2024-10-19 20:00:00+00:00', '2024-10-19 21:00:00+00:00',\n",
            " '2024-10-19 22:00:00+00:00', '2024-10-19 23:00:00+00:00']\n",
            "Length: 401496, dtype: datetime64[ns, UTC]\n",
            "Number of unique values: 401496\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'timezone':\n",
            "[-18000 -14400 -21600]\n",
            "Number of unique values: 3\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'fecha_local':\n",
            "<DatetimeArray>\n",
            "['1978-12-31 19:00:00', '1978-12-31 20:00:00', '1978-12-31 21:00:00',\n",
            " '1978-12-31 22:00:00', '1978-12-31 23:00:00', '1979-01-01 00:00:00',\n",
            " '1979-01-01 01:00:00', '1979-01-01 02:00:00', '1979-01-01 03:00:00',\n",
            " '1979-01-01 04:00:00',\n",
            " ...\n",
            " '2024-10-19 09:00:00', '2024-10-19 10:00:00', '2024-10-19 11:00:00',\n",
            " '2024-10-19 12:00:00', '2024-10-19 13:00:00', '2024-10-19 14:00:00',\n",
            " '2024-10-19 15:00:00', '2024-10-19 16:00:00', '2024-10-19 17:00:00',\n",
            " '2024-10-19 18:00:00']\n",
            "Length: 401495, dtype: datetime64[ns]\n",
            "Number of unique values: 401495\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'year':\n",
            "[1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991\n",
            " 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005\n",
            " 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n",
            " 2020 2021 2022 2023 2024]\n",
            "Number of unique values: 47\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'month':\n",
            "[12  1  2  3  4  5  6  7  8  9 10 11]\n",
            "Number of unique values: 12\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'day':\n",
            "[31  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30]\n",
            "Number of unique values: 31\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'hour':\n",
            "[19 20 21 22 23  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
            "Number of unique values: 24\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'lat':\n",
            "[-1.254341 -2.900129  0.970581 -2.189134  0.347147  0.112778 -3.995207\n",
            " -3.258111 -0.967653 -2.882745 -1.492881 -1.022512 -0.223252 -0.639359\n",
            " -0.253841 -4.062094]\n",
            "Number of unique values: 16\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'lon':\n",
            "[-78.62285 -79.0059  -79.653   -79.8899  -78.13236 -76.91194 -79.20221\n",
            " -79.95539 -80.70891 -77.68781 -77.9998  -79.4604  -78.51411 -90.33719\n",
            " -79.17633 -78.94862]\n",
            "Number of unique values: 16\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'temp':\n",
            "[15.88 15.12 14.59 ...  4.17  3.97  3.57]\n",
            "Number of unique values: 3341\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'visibility':\n",
            "[      nan 1.500e+03 3.000e+02 1.000e+04 2.000e+03 6.000e+03 6.000e+02\n",
            " 1.000e+03 8.000e+02 2.800e+03 3.200e+03 1.000e+02 3.800e+03 4.000e+03\n",
            " 3.000e+03 8.000e+03 5.000e+03 7.000e+03 4.500e+03 4.700e+03 1.300e+03\n",
            " 2.600e+03 2.200e+03 5.000e+02 2.000e+02 1.200e+03 4.000e+02 3.600e+03\n",
            " 2.100e+03 9.999e+03 9.000e+03 4.200e+03 9.900e+03 7.000e+02 1.700e+03\n",
            " 4.100e+03 2.500e+03 1.800e+03 4.600e+03 3.900e+03 3.300e+03 1.600e+03\n",
            " 2.300e+01 2.700e+01 3.290e+03 3.100e+03 8.880e+02 1.002e+03 4.900e+03\n",
            " 4.800e+03 1.900e+03 9.890e+02 9.930e+02 2.400e+03 9.000e+02 3.500e+03\n",
            " 1.100e+03 3.400e+03 2.300e+03 8.200e+02 2.101e+03 9.995e+03 9.990e+03\n",
            " 5.999e+03 5.006e+03 6.666e+03 9.599e+03 9.959e+03 9.990e+02 5.599e+03\n",
            " 8.080e+03 9.993e+03 1.999e+03 9.991e+03 6.008e+03 4.828e+03 3.218e+03\n",
            " 8.050e+02 8.046e+03 9.656e+03 2.011e+03 1.006e+03 1.609e+03 6.437e+03\n",
            " 8.888e+03 2.206e+03 2.108e+03 2.009e+03 2.210e+03 2.110e+03 2.005e+03\n",
            " 2.301e+03 2.007e+03 2.208e+03 4.040e+02 2.006e+03 2.004e+03 1.804e+03\n",
            " 2.008e+03 2.207e+03 9.099e+03 9.699e+03 1.802e+03 2.305e+03 2.003e+03\n",
            " 1.902e+03 7.010e+02 1.100e+01 9.899e+03 3.500e+02 3.300e+02 4.400e+03\n",
            " 1.400e+03 4.900e+01 1.700e+01 1.400e+01 9.998e+03 9.900e+01 9.595e+03\n",
            " 9.939e+03 4.023e+03 8.001e+03 9.919e+03 9.199e+03 9.989e+03 2.816e+03\n",
            " 3.700e+03 4.830e+02 9.050e+02 2.604e+03 7.003e+03 1.502e+03 2.808e+03\n",
            " 2.307e+03 9.020e+02 2.909e+03 3.009e+03 2.001e+03 2.102e+03 2.104e+03\n",
            " 2.002e+03 2.403e+03 2.804e+03 3.330e+03 1.905e+03 8.010e+03 2.109e+03\n",
            " 2.700e+03 2.012e+03 2.203e+03 9.800e+03 1.900e+01 9.000e+00 3.007e+03\n",
            " 5.000e+01 3.999e+03 2.907e+03 8.800e+03 8.200e+03 8.900e+03 6.800e+03\n",
            " 8.300e+03 8.700e+03 9.700e+03 6.080e+03 8.999e+03 6.040e+03 4.080e+03\n",
            " 6.010e+03 6.100e+03 5.010e+02 4.010e+03 2.414e+03 4.999e+03 7.050e+02\n",
            " 6.020e+02 1.030e+02 3.405e+03 3.002e+03 8.030e+02 8.020e+02 7.040e+02\n",
            " 2.030e+02 3.301e+03 1.004e+03 3.306e+03 3.201e+03 9.400e+03 3.103e+03\n",
            " 9.010e+02 3.302e+03]\n",
            "Number of unique values: 191\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'dew_point':\n",
            "[14.07 13.49 12.8  ... 29.68 29.54 30.23]\n",
            "Number of unique values: 3993\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'feels_like':\n",
            "[15.85 15.04 14.43 ...  1.6   2.33 41.53]\n",
            "Number of unique values: 3995\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'temp_min':\n",
            "[13.33 12.38 12.11 ... 35.2   2.45  1.42]\n",
            "Number of unique values: 3407\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'temp_max':\n",
            "[17.21 16.64 15.95 ...  4.72  2.97 36.28]\n",
            "Number of unique values: 3300\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'pressure':\n",
            "[1015 1016 1017 1018 1019 1020 1014 1013 1021 1012 1011 1022 1023 1024\n",
            " 1025 1026 1027 1028 1010 1009 1008 1029 1007 1006 1005 1004 1003 1002\n",
            " 1001]\n",
            "Number of unique values: 29\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'humidity':\n",
            "[ 89  90  98  99  97  91  87  64  55  52  57  58  73  75  78  86  94 100\n",
            "  96  70  71  66  67  69  76  81  92  93  74  59  61  65  79  77  83  72\n",
            "  95  82  80  84  62  85  88  68  56  63  53  54  60  51  49  46  47  48\n",
            "  41  40  38  33  35  43  45  36  39  34  44  50  42  37  31  30  27  29\n",
            "  28  32  22  23  20  26  25  24  21  18  19  15  14  16  17   1   8  11\n",
            "   5  10  12  13   9   6   7   3   2   4]\n",
            "Number of unique values: 100\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'wind_speed':\n",
            "[1.88 1.68 1.51 ... 8.68 8.69 8.54]\n",
            "Number of unique values: 1081\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'wind_deg':\n",
            "[112 101 103 107 111 116 120 123 134 158 146 147 135 117 105 114 115 102\n",
            " 104 132 140 127 122 108 113 110 125  93 100 109 106 157  95  96  99 119\n",
            "  98 121 130 129 133 143 124 172 261 203 248 268 287 168 241 179 356 211\n",
            " 164 262 283 278 265 257 240 222 204 221 276 260 246  97 131 128 118 144\n",
            " 142 137 302 270 215 151 138 136 126  92  82  84  85 161 152 150 200 312\n",
            " 198 190 298 317 307 279  88  87  71  29 332 310 263 251 236 202 188  94\n",
            " 173 325  54  68 183 284 300 288 291 286 229  86  79 139 176 178  80 159\n",
            " 156 174  89 166 177 149  90 169 145  48   2 311 303 304 244 282 290 232\n",
            " 264  83  63  75  67  77 155 195 224 162 141 207 199 170 153 271 234 160\n",
            " 225 238 185 292 187 165 171  59  81  74 219 154  58  91 258 275 357 336\n",
            " 319 294 289 274 210 350  46 267 269 327 243 277 280 206  65  78 192 148\n",
            " 226 233 306 313 272 250 239 209 227  15 252 249 184 163 167 235 253 254\n",
            " 295  32 242 181 196 175 212 230 344  76  69 218 285 266 273 255  36 220\n",
            " 299 335 297 338 309 201 301 216 217 186 191   0  70 213 193 197 328 296\n",
            " 308 259  35  45  72 194 247 256 205 293  14 281 189 245  42  18 314 214\n",
            "  61 321 326 228 305  44  51  38  22 333 348  23 334 180 182 237  10 318\n",
            " 345  37  73 331 349  24  50 353 342 358 315 231  60 359 330  40 339   1\n",
            "  21 337  27  64 324  55  12 341 316 322  52   6  62  39 352 320 208  66\n",
            "  56  57 360 351 323 329 223  53  34 343  28  49   5  26   7  16  20   3\n",
            "  25  30  19  33  13   9  41  11   8 340  31  43 354   4 346  47 347 355\n",
            "  17]\n",
            "Number of unique values: 361\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'wind_gust':\n",
            "[      nan 0.000e+00 7.710e+00 5.140e+00 2.570e+00 3.600e+00 6.170e+00\n",
            " 1.028e+01 8.740e+00 1.439e+01 1.285e+01 1.131e+01 1.030e+00 1.645e+01\n",
            " 3.080e+00 1.542e+01 1.696e+01 1.953e+01 9.250e+00 1.234e+01 1.388e+01\n",
            " 1.491e+01 4.110e+00 5.650e+00 1.540e+00 9.770e+00 1.079e+01 1.182e+01\n",
            " 1.336e+01 2.060e+00 6.680e+00 1.748e+01 7.200e+00 2.240e+00 4.470e+00\n",
            " 5.360e+00 6.710e+00 7.600e+00 1.118e+01 9.830e+00 8.940e+00 3.130e+00\n",
            " 8.900e-01 4.020e+00 6.260e+00 1.162e+01 5.810e+00 1.252e+01 1.431e+01\n",
            " 1.341e+01 2.680e+00 1.340e+00 3.580e+00 4.500e-01 7.150e+00 9.390e+00\n",
            " 8.050e+00 1.073e+01 1.386e+01 1.699e+01 8.100e-01 2.630e+00 1.600e+00\n",
            " 1.820e+00 1.300e+00 1.620e+00 2.040e+00 1.420e+00 2.230e+00 1.210e+00\n",
            " 8.700e-01 2.530e+00 1.720e+00 1.200e+00 1.020e+00 1.730e+00 2.330e+00\n",
            " 1.610e+00 7.400e-01 1.310e+00 7.100e-01 1.630e+00 1.510e+00 2.950e+00\n",
            " 3.300e+00 3.620e+00 3.640e+00 1.640e+00 4.530e+00 4.400e+00 3.800e+00\n",
            " 3.220e+00 5.410e+00 5.400e+00 2.620e+00 3.920e+00 2.220e+00 2.820e+00\n",
            " 2.540e+00 3.940e+00 3.610e+00 4.240e+00 2.050e+00 4.160e+00 3.820e+00\n",
            " 3.950e+00 3.960e+00 2.510e+00 4.510e+00 3.810e+00 3.150e+00 1.970e+00\n",
            " 2.010e+00 2.340e+00 2.700e+00 1.130e+00 1.020e+01 1.030e+01 9.300e+00\n",
            " 6.200e+00 8.700e+00 1.290e+01 9.800e+00 1.080e+01 7.700e+00 1.230e+01\n",
            " 8.200e+00 1.130e+01 9.260e+00 1.029e+01 8.750e+00 1.235e+01 1.132e+01\n",
            " 1.286e+01 1.180e+01 5.660e+00 1.390e+01 1.338e+01 1.440e+01 6.700e+00\n",
            " 1.389e+01 1.183e+01 1.340e+01 7.720e+00 6.690e+00 8.800e+00 1.490e+01\n",
            " 1.543e+01 1.010e+00 1.530e+00 1.700e+00 2.150e+00 1.660e+00 1.840e+00\n",
            " 1.000e+00 1.220e+00 8.400e-01 8.300e-01 3.300e-01 5.000e-01 5.700e-01\n",
            " 1.230e+00 6.200e-01 6.500e-01 1.280e+00 2.030e+00 9.300e-01 4.300e-01\n",
            " 9.200e-01 1.950e+00 1.140e+00 1.930e+00 1.800e+00 1.900e+00 2.430e+00\n",
            " 3.020e+00 2.710e+00 3.110e+00 3.000e+00 2.830e+00 2.910e+00 1.740e+00\n",
            " 1.940e+00 1.240e+00 2.120e+00 8.500e-01 2.160e+00 2.420e+00 2.850e+00\n",
            " 3.100e+00 2.350e+00 2.090e+00 2.670e+00 1.770e+00 1.450e+00 2.800e+00\n",
            " 6.300e-01 8.230e+00 5.210e+00 5.130e+00 5.000e+00 4.620e+00 4.870e+00\n",
            " 6.600e+00 6.820e+00 6.940e+00 6.220e+00 4.820e+00 3.830e+00 4.000e+00\n",
            " 4.370e+00 4.720e+00 4.200e+00 4.030e+00 4.220e+00 3.650e+00 3.230e+00\n",
            " 2.930e+00 3.840e+00 3.910e+00 4.210e+00 4.230e+00 4.540e+00 4.830e+00\n",
            " 4.100e+00 4.520e+00 5.240e+00 5.630e+00 4.930e+00 6.300e+00 7.500e+00\n",
            " 7.430e+00 4.640e+00 4.320e+00 2.730e+00 3.730e+00 3.720e+00 4.920e+00\n",
            " 5.320e+00 5.600e+00 3.440e+00 3.240e+00 2.940e+00 4.310e+00 3.140e+00\n",
            " 3.340e+00 3.260e+00 4.350e+00 3.750e+00 4.050e+00 4.380e+00 4.290e+00\n",
            " 4.630e+00 6.140e+00 7.300e+00 6.040e+00 5.610e+00 5.930e+00 3.860e+01\n",
            " 1.540e+01 5.700e+00 5.100e+00 1.700e+01 1.240e+01 1.852e+01 1.790e+00\n",
            " 8.490e+00 5.330e+00 2.270e+00 2.550e+00 1.520e+00 6.530e+00 3.310e+00\n",
            " 3.370e+00 3.630e+00 1.850e+00 7.510e+00 3.430e+00 2.440e+00 3.250e+00\n",
            " 3.120e+00 1.920e+00 1.830e+00 1.400e+00 1.710e+00 3.050e+00 2.320e+00\n",
            " 2.360e+00 5.910e+00 3.710e+00 2.380e+00 4.140e+00 3.200e+00 1.070e+00\n",
            " 1.350e+00 3.160e+00 2.400e+00 4.200e-01 8.200e-01 1.110e+00 4.000e-01\n",
            " 7.700e-01 7.300e-01 2.020e+00 5.500e-01 1.180e+00 3.030e+00 2.410e+00\n",
            " 6.400e-01 6.100e-01 7.000e-01 2.740e+00 2.720e+00 4.850e+00 1.330e+00\n",
            " 1.500e+00 9.000e-01 6.430e+00 5.220e+00 3.210e+00 3.900e+00 4.500e+00\n",
            " 3.930e+00 1.320e+00 7.200e-01 2.200e+00 2.640e+00 3.100e-01 1.150e+00\n",
            " 1.060e+00 1.650e+00 2.460e+00 1.410e+00 5.100e-01 2.180e+00 3.570e+00\n",
            " 9.500e-01 2.300e+00 3.910e+01 1.170e+00 3.560e+00 6.000e-01 6.700e-01\n",
            " 1.120e+00 7.800e-01 2.210e+00 1.040e+00 1.430e+00 2.130e+00 3.040e+00\n",
            " 6.100e+00 8.000e-01 9.100e-01 9.400e-01 2.310e+00 1.260e+00 1.560e+00\n",
            " 1.050e+00 1.580e+00 1.590e+00 1.470e+00 5.300e-01 9.530e+00 1.330e+01\n",
            " 1.800e+01 1.650e+01 1.600e+01 1.646e+01 1.850e+01 1.590e+01 1.750e+01\n",
            " 1.492e+02 1.960e+01 1.595e+01 1.698e+01 1.749e+01 1.492e+01 1.654e+01\n",
            " 1.609e+01 1.565e+01 1.520e+01 1.207e+01 1.475e+01 1.296e+01 5.200e-01\n",
            " 9.700e-01 2.840e+00 1.480e+00 4.100e-01 4.430e+00 4.130e+00 2.450e+00\n",
            " 5.600e-01 2.960e+00 2.580e+00 3.990e+00 2.470e+00 5.400e-01 2.660e+00\n",
            " 1.910e+00 1.370e+00 2.110e+00 7.500e-01 4.400e-01 1.100e+00 2.600e+00\n",
            " 2.650e+00 1.860e+00 1.250e+00 2.010e+01 1.950e+01 3.290e+01 1.900e+01\n",
            " 2.310e+01 8.040e+00 8.340e+00 5.920e+00 6.810e+00 5.830e+00 5.030e+00\n",
            " 6.210e+00 5.420e+00 4.840e+00 8.300e+00 7.400e+00 7.030e+00 7.540e+00\n",
            " 7.420e+00 4.700e+00 6.120e+00 5.350e+00 4.120e+00 5.110e+00 5.540e+00\n",
            " 4.750e+00 8.010e+00 8.440e+00 7.800e+00 7.140e+00 8.910e+00 2.520e+00\n",
            " 2.000e+00 1.380e+00 2.140e+00 2.610e+00 2.500e+00 2.560e+00 2.480e+00\n",
            " 1.690e+00 2.870e+00 1.870e+00 2.100e+00 2.170e+00 9.600e-01 2.070e+00\n",
            " 5.800e-01 1.550e+00 3.520e+00 3.530e+00 1.160e+00 1.810e+00 1.490e+00\n",
            " 5.530e+00 4.300e+00 1.570e+00 1.460e+00 5.520e+00 5.840e+00 3.320e+00\n",
            " 2.920e+00 2.750e+00 4.800e-01 3.410e+00 3.510e+00 2.810e+00 5.250e+00\n",
            " 3.500e+00 1.750e+00 6.030e+00 5.900e+00 4.610e+00 5.510e+00 4.440e+00\n",
            " 3.860e+00 7.110e+00 4.710e+00 4.010e+00 1.090e+00 1.670e+00 5.230e+00\n",
            " 6.350e+00 6.610e+00 5.040e+00 3.700e+00 1.640e+01 1.280e+01 1.380e+01\n",
            " 9.200e+00 9.700e+00 2.050e+01 8.600e-01 9.800e-01 1.390e+00 4.800e+00\n",
            " 5.470e+00 5.850e+00 6.460e+00 6.340e+00 6.000e+00 5.720e+00 5.500e+00\n",
            " 6.630e+00 6.410e+00 5.370e+00 6.110e+00 6.420e+00 5.800e+00 6.480e+00\n",
            " 6.230e+00 4.910e+00 4.040e+00 5.310e+00 5.640e+00 5.200e+00 5.820e+00\n",
            " 5.340e+00 5.620e+00 4.410e+00 4.420e+00 4.900e+00 5.450e+00 6.540e+00\n",
            " 6.150e+00 5.160e+00 4.860e+00 3.850e+00 4.080e+00 4.190e+00 4.570e+00\n",
            " 4.970e+00 4.810e+00 4.600e+00 6.330e+00 3.330e+00 1.270e+00 8.800e-01\n",
            " 5.710e+00 2.900e+00 6.620e+00 4.940e+00 1.440e+00 6.050e+00 3.760e+00\n",
            " 1.290e+00 4.250e+00 1.400e-01 3.740e+00 1.360e+00 4.450e+00 4.090e+00\n",
            " 3.010e+00]\n",
            "Number of unique values: 561\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'rain_1h':\n",
            "[  nan  0.1   0.32 ... 12.18 19.65 12.84]\n",
            "Number of unique values: 1909\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'rain_3h':\n",
            "[  nan  1.    0.25  4.19  1.25  5.69  0.81  0.5   0.69  2.25  0.19  4.75\n",
            "  3.13  0.31  0.13  1.69  1.13  1.5   1.19  4.06  2.    0.56  1.88  0.38\n",
            "  1.56  2.94  2.63  1.94  0.75  0.88  0.94  0.44  3.    3.88  2.69  2.19\n",
            "  4.63  2.81  3.44  1.31  1.63  1.06  0.63  2.56  2.44  8.    1.44  2.75\n",
            "  2.31  3.63  4.    3.75  1.75 13.25  4.88  2.38  2.88  3.06  5.25  2.5\n",
            "  4.56  3.25  0.8   3.56  5.38  3.94  1.38  7.    9.81 49.    2.06]\n",
            "Number of unique values: 71\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'clouds_all':\n",
            "[ 44  92  93  95  96  99 100  98  97  85  61  49  54  33  39  58  45  53\n",
            "  51  72  79  80  91  69  81  46  74  87  90  47  52  70  94  82  41  55\n",
            "  63  78  76  68  56  67  88  71  66  59  86  37  42  35  84  62  83  57\n",
            "  40  60  22  29  31  32  38  73  64  77  17  34  14   9  13  65  75  30\n",
            "  43  15  24  12  16   8  11  23  26   7   5  89  28  19  20  48  36  50\n",
            "  18  27   6  21  10   1   2   3  25   0   4]\n",
            "Number of unique values: 101\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'weather_id':\n",
            "[802 804 500 803 501 801 800 502 741 721 300 211 711 701 301 310 520 761\n",
            " 201 302 521 311 200 503 731 202 771 781 762 230 210 522 312 611 612]\n",
            "Number of unique values: 35\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'weather_main':\n",
            "['Clouds', 'Rain', 'Clear', 'Fog', 'Haze', ..., 'Dust', 'Squall', 'Tornado', 'Ash', 'Snow']\n",
            "Length: 14\n",
            "Categories (14, object): ['Ash', 'Clear', 'Clouds', 'Drizzle', ..., 'Dust', 'Snow', 'Squall',\n",
            "                          'Tornado']\n",
            "Number of unique values: 14\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'weather_description':\n",
            "['scattered clouds', 'overcast clouds', 'light rain', 'broken clouds', 'moderate rain', ..., 'light thunderstorm', 'heavy intensity shower rain', 'heavy intensity rain and drizzle', 'sleet', 'light shower sleet']\n",
            "Length: 37\n",
            "Categories (37, object): ['broken clouds', 'drizzle', 'few clouds', 'fog', ..., 'proximity tornado',\n",
            "                          'sleet', 'very heavy rain', 'heavy intensity rain and drizzle']\n",
            "Number of unique values: 37\n",
            "------------------------------------------------------------\n",
            "\n",
            "Column 'weather_icon':\n",
            "['03n', '04n', '04d', '10d', '03d', ..., '50n', '09n', '11n', '13d', '13n']\n",
            "Length: 18\n",
            "Categories (18, object): ['01d', '01n', '02d', '02n', ..., '50d', '50n', '13d', '13n']\n",
            "Number of unique values: 18\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing values"
      ],
      "metadata": {
        "id": "hD9i44oKAkfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze missing values\n",
        "missing_values = data.isnull().sum()\n",
        "missing_percentage = (missing_values / len(data)* 100).round(4)\n",
        "\n",
        "# Display columns with missing values and their percentages\n",
        "missing_data_summary = missing_values[missing_values > 0].to_frame(name=\"Missing Count\")\n",
        "missing_data_summary[\"Missing Percentage\"] = missing_percentage[missing_values > 0]\n",
        "missing_data_summary"
      ],
      "metadata": {
        "id": "m08u0zG4AfE7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "e7509f37-32dc-4cb9-fcf9-73cc3f862211"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Missing Count  Missing Percentage\n",
              "visibility        5409494             83.9220\n",
              "wind_gust         6389392             99.1240\n",
              "rain_1h           4134594             64.1434\n",
              "rain_3h           6444360             99.9768"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3e50578-dfa7-48f4-b8fd-05ae7b6706e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Count</th>\n",
              "      <th>Missing Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>visibility</th>\n",
              "      <td>5409494</td>\n",
              "      <td>83.9220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wind_gust</th>\n",
              "      <td>6389392</td>\n",
              "      <td>99.1240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rain_1h</th>\n",
              "      <td>4134594</td>\n",
              "      <td>64.1434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rain_3h</th>\n",
              "      <td>6444360</td>\n",
              "      <td>99.9768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3e50578-dfa7-48f4-b8fd-05ae7b6706e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3e50578-dfa7-48f4-b8fd-05ae7b6706e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3e50578-dfa7-48f4-b8fd-05ae7b6706e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_2dcda79d-e963-4369-9c47-8c7c5e9eb037\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('missing_data_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2dcda79d-e963-4369-9c47-8c7c5e9eb037 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('missing_data_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "missing_data_summary",
              "summary": "{\n  \"name\": \"missing_data_summary\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Missing Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1083154,\n        \"min\": 4134594,\n        \"max\": 6444360,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6389392,\n          6444360,\n          5409494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Missing Percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.80389990637094,\n        \"min\": 64.1434,\n        \"max\": 99.9768,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          99.124,\n          99.9768,\n          83.922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}